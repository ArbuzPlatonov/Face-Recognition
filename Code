import face_recognition
from PIL import Image, ImageDraw
import os
import sys
import pickle
import cv2
import mediapipe as mp
import time
import pandas

#The function of determining the main points of the face
def face_rec():
    gal_face_img = face_recognition.load_image_file('img/gal.jpg')
    gal_face_location = face_recognition.face_locations(gal_face_img)
    gal_face_landmarks = face_recognition.face_landmarks(gal_face_img)
    print(gal_face_location)
    print(gal_face_landmarks)

    pil_img = Image.fromarray(gal_face_img)
    draw = ImageDraw.Draw(pil_img)

    for(top, right, bottom, left) in gal_face_location:
        draw.rectangle(((left, top),(right, bottom)), outline=(255,0,0), width = 8)
    del draw
    pil_img.save('img/new_gal.jpg')
#Determining the presence of a person
def extra_face(img_path):
    count = 0
    faces = face_recognition.load_image_file(img_path)
    faces_locations = face_recognition.face_locations(faces)

    for face_location in faces_locations:
        top, right, bottom, left = face_location

        face_img = faces[top:bottom, left:right]
        pil_img = Image.fromarray(face_img)
        pil_img.save(f'img/{count}face_img.jpg')
        count += 1
    return f"Found {count} face(s) in this pfoto"


#Face comparison function
def compare_faces(img1_path, img2_path):
    img1 = face_recognition.load_image_file(img1_path)
    img1_encodings = face_recognition.face_encodings(img1)[0]
    #print(img1_encodings)

    img2 = face_recognition.load_image_file(img2_path)
    img2_encodings = face_recognition.face_encodings(img2)[0]

    result = face_recognition.compare_faces([img1_encodings], img2_encodings)
    print(result)

#Neural network learning function
def train_model(name):

    if not os.path.exists("dataset"):
        print("[ERROR] there is no directory 'dataset'")
        sys.exit()
    knows_encodings = []
    images = os.listdir('dataset')

    print(images)

    for(i, image) in enumerate(images):
        print(f"[+] processing img {i + 1}/ {len(images)}")
        print(image)

        face_img = face_recognition.load_image_file(f"dataset/{image}")
        face_enc = face_recognition.face_encodings(face_img)[0]

        print(face_enc)

        if len(knows_encodings) == 0:
            knows_encodings.append(face_enc)
        else:
            for item in range(0, len(knows_encodings)):
                result = face_recognition.compare_faces([face_enc], knows_encodings [item])
                print(result)

                if result[0]:
                    knows_encodings.append(face_enc)
                    print('Same person!')
                    break
                else:
                    print("Another person")
                    break


    print(knows_encodings)
    print(f"Length {len(knows_encodings)}")


    data = {
        "name" : name,
        "encodings" : knows_encodings
    }

    with open(f"{name}_encodings.pickle", "wb") as file:
        file.write(pickle.dumps(data))

    return f"[INFO] File {name}_encodings.pickle successfully created"
#The function of saving video from the webcam stream
def save_video():
    cap = cv2.VideoCapture(0)
    frame_width = int(cap.get(3))
    frame_height = int(cap.get(4))
    frame_size = (frame_width,frame_height)
    output = cv2.VideoWriter('video/video.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 60, frame_size)
    while(cap.isOpened()):
        ret, frame = cap.read()
        if ret == True:
            output.write(frame)
        else:
            print('Stream disconnected')
            break


#The function of creating screenshots from videos
def take_screenshot_from_video():
    #save_video()
    capture = cv2.VideoCapture('video/video.avi')
    count = 0


    if not os.path.exists("dataset_from_video"):
        os.mkdir("dataset_from_video")


    while True:
        ret, frame = capture.read()
        fps = capture.get(cv2.CAP_PROP_FPS)
        multiplier = fps * 2
        #print(fps)

        if ret:
            frame_id = int(round(capture.get(1)))
            #print(frame_id)
            cv2.imshow("frame", frame)
            cv2.waitKey(60)

            if frame_id % multiplier == 0 and count != 11:
                cv2.imwrite(f"dataset_from_video/{count}.jpg", frame)
                print(f"Take a screenshot {count}")
                count += 1
        else:
            print("[ERROR] Can't get the frame . . . ")
            break
    capture.release()
    cv2.destroyAllWindows()

#The function of determining a person using a trained neural network
def detect_person_in_video():
    data = pickle.loads(open('Skala_encodings.pickle','rb').read())
    video = cv2.VideoCapture(0)

    while True:
        ret, image = video.read()

        location = face_recognition.face_locations(image, model='hog')
        encodings = face_recognition.face_encodings(image, location)
        for face_encodings, face_location in zip(encodings, location):
            resultion = face_recognition.compare_faces(data['encodings'], face_encodings)
            match = None

            if True in resultion:
                match = data['name']
                print(f'Match found! {match}')
            else:
                print('Alarm!')
            
            left_top = (face_location[3], face_location[0])
            right_bottom = (face_location[1], face_location[2])
            color = [0, 255, 0]
            cv2.rectangle(image, left_top, right_bottom, color, 4)
        
        cv2.imshow("detect_person_in_video", image)

        k = cv2.waitKey(20)
        if k == ord('q'):
            print('extra closing')
            break
#The function of creating a triangulation mask
def mask():
    cap = cv2.VideoCapture("IMG_6805.MOV")
    pTime = 0   
    mpDraw = mp.solutions.drawing_utils
    mp_drawing = mp.solutions.drawing_utils
    mpFaceMesh = mp.solutions.face_mesh
    mp_drawing_styles = mp.solutions.drawing_styles
    faceMesh = mpFaceMesh.FaceMesh(max_num_faces = 2)
    drawing_spec = mp_drawing.DrawingSpec(color=(255,0,0),thickness=1, circle_radius=3)

    while True:
        success, img = cap.read()
        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = faceMesh.process(imgRGB)
        if results.multi_face_landmarks:
            for faceLms in results.multi_face_landmarks:
                mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACEMESH_TESSELATION, drawing_spec, mp_drawing_styles
            .get_default_face_mesh_tesselation_style())


        cTime = time.time()
        fps = 1 / (cTime - pTime)
        pTime = cTime
        cv2.putText(img, f'FPS:{int(fps)}',(20,70),cv2.FONT_HERSHEY_PLAIN, 3,(0,255,0),3)
        cv2.imshow("Image", img)
        cv2.waitKey(5)








#The function of launching other functions
def main():
    #face_rec()
    #print(extra_face('img/gal.jpg'))
    #compare_faces('img/gal.jpg', 'img/obama.jpg' )
    print(train_model("Platon"))
    #take_screenshot_from_video()
    #save_video()
    #detect_person_in_video()
    #mask()
    

if __name__ == '__main__':
    main()
